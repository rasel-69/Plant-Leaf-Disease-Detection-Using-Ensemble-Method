# ============================
# IMPORTS
# ============================
import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score, classification_report

# ============================
# BASE MODEL DEFINITIONS
# ============================
def build_mobilenetv3(num_classes, img_height, img_width):
    base = tf.keras.applications.MobileNetV3Large(
        input_shape=(img_height, img_width, 3),
        include_top=False,
        weights='imagenet'
    )
    base.trainable = False  # freeze backbone

    model = models.Sequential([
        base,

        # Custom convs
        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(2, 2)),

        layers.Conv2D(128, (5, 5), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(2, 2)),

        layers.GlobalAveragePooling2D(),

        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.4),

        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.3),

        layers.Dense(num_classes, activation='softmax')
    ])
    return model


def build_convnext(num_classes=21, img_height=224, img_width=224):
    act = tf.nn.swish
    base = tf.keras.applications.ConvNeXtSmall(
        input_shape=(img_height, img_width, 3),
        include_top=False,
        weights='imagenet'
    )
    base.trainable = False
    inputs = tf.keras.Input(shape=(img_height, img_width, 3))
    x = base(inputs)

    # conv layers
    x = layers.Conv2D(256, 3, padding='same', activation=act)(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D(2)(x)

    x = layers.Conv2D(128, 3, padding='same', activation=act)(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D(2)(x)

    x = layers.Conv2D(56, 3, padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)

    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.4)(x)

    x = layers.Dense(256, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.3)(x)

    out = layers.Dense(num_classes, activation='softmax')(x)
    return tf.keras.Model(inputs, out)


def inception_block(x):
    act = tf.nn.swish

    p1 = layers.Conv2D(84, 1, padding='same', activation='relu')(x)

    p2 = layers.Conv2D(16, 1, padding='same', activation=act)(x)
    p2 = layers.Conv2D(32, 3, padding='same', activation=act)(p2)

    p3 = layers.Conv2D(8, 1, padding='same', activation=act)(x)
    p3 = layers.Conv2D(16, 5, padding='same', activation=act)(p3)

    p4 = layers.MaxPooling2D(3, strides=1, padding='same')(x)
    p4 = layers.Conv2D(8, 1, padding='same', activation='relu')(p4)

    p5 = layers.Conv2D(16, 7, padding='same', activation=act)(x)

    p6 = layers.Conv2D(8, 1, padding='same', activation='relu')(x)
    p6 = layers.MaxPooling2D(3, strides=1, padding='same')(x)
    p6 = layers.Conv2D(16, 1, padding='same', activation='relu')(p6)

    return layers.Concatenate(axis=-1)([p1, p2, p3, p4, p5, p6])


def build_custom_googlenet(input_shape=(224, 224, 3), num_classes=21):
    inp = layers.Input(shape=input_shape)
    x = layers.Conv2D(24, 3, strides=2, padding='same', activation='relu')(inp)
    x = layers.MaxPooling2D(2, strides=1, padding='same')(x)

    x = layers.Conv2D(24, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(18, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(18, 2, padding='same', activation='relu')(x)
    x = layers.Conv2D(12, 2, padding='same', activation='relu')(x)
    x = layers.MaxPooling2D(2, strides=2, padding='same')(x)

    x = inception_block(x)
    x = layers.MaxPooling2D(2, strides=2, padding='same')(x)

    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(80, activation='relu')(x)
    x = layers.Dense(40, activation='relu')(x)
    out = layers.Dense(num_classes, activation='softmax')(x)
    return models.Model(inp, out)






# ============================
# FEATURE EXTRACTION HELPERS
# ============================
def get_feature_extractor(full_model):
    """remove last softmax layer for embeddings."""
    # Explicitly create a new model from input to the second to last layer
    return tf.keras.Model(inputs=full_model.inputs,
                          outputs=full_model.layers[-2].output)


def extract_features(model, dataset):
    """extract penultimate features + labels from dataset."""
    features, labels = [], []
    for bx, by in dataset:
        preds = model.predict(bx, verbose=0)
        features.append(preds)
        labels.append(tf.argmax(by, axis=1).numpy())
    return np.concatenate(features), np.concatenate(labels)




img_height, img_width = 224, 224
num_classes = 21

train_dir = "/content/drive/MyDrive/plantLeaf/plant_disease_flat_split/train"
val_dir   = "/content/drive/MyDrive/plantLeaf/plant_disease_flat_split/val"

train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir, image_size=(img_height, img_width),
    batch_size=32, label_mode="categorical"
)
val_ds = tf.keras.utils.image_dataset_from_directory(
    val_dir, image_size=(img_height, img_width),
    batch_size=32, label_mode="categorical"
)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().prefetch(AUTOTUNE)
val_ds   = val_ds.cache().prefetch(AUTOTUNE)



mobilenet_model = build_mobilenetv3(num_classes, img_height, img_width)
convnext_model  = build_convnext(num_classes, img_height, img_width)
googlenet_model = build_custom_googlenet((img_height, img_width, 3), num_classes)

# Build the models by calling them on dummy inputs
dummy_input = tf.zeros((1, img_height, img_width, 3))
_ = mobilenet_model(dummy_input)
_ = convnext_model(dummy_input)
_ = googlenet_model(dummy_input)


mobilenet_extractor = get_feature_extractor(mobilenet_model)
convnext_extractor  = get_feature_extractor(convnext_model)
googlenet_extractor = get_feature_extractor(googlenet_model)


# FEATURE FUSION FOR CATBOOST

# Training features
feat1_train, y_train = extract_features(mobilenet_extractor, train_ds)
feat2_train, y_train   = extract_features(convnext_extractor, train_ds)
feat3_train, y_train     = extract_features(googlenet_extractor, train_ds)
X_train = np.concatenate([feat1_train, feat2_train, feat3_train], axis=1)

# Validation features
feat1_val, y_val = extract_features(mobilenet_extractor, val_ds)
feat2_val, y_val    = extract_features(convnext_extractor, val_ds)
feat3_val, y_val   = extract_features(googlenet_extractor, val_ds)
X_val = np.concatenate([feat1_val, feat2_val, feat3_val], axis=1)



# CATBOOST META-LEARNER

cat_model = CatBoostClassifier(
    iterations=1200,
    depth=8,
    learning_rate=0.05,
    loss_function='MultiClass',
    eval_metric='Accuracy',
    verbose=200,
    task_type="GPU"  # drop if no GPU
)

cat_model.fit(
    X_train, y_train,
    eval_set=(X_val, y_val),
    early_stopping_rounds=100
)




